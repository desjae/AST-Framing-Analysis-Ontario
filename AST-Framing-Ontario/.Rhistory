school_top_terms %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(beta, term, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
scale_y_reordered()
consortia_top_terms <- consortia_topics %>%
group_by(topic) %>%
slice_max(beta, n = 10) %>%
ungroup() %>%
arrange(topic, -beta)
consortia_top_terms %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(beta, term, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
scale_y_reordered()
policy_top_terms <- policy_topics %>%
group_by(topic) %>%
slice_max(beta, n = 10) %>%
ungroup() %>%
arrange(topic, -beta)
policy_top_terms %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(beta, term, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
scale_y_reordered()
academic_top_terms <- academic_topics %>%
group_by(topic) %>%
slice_max(beta, n = 10) %>%
ungroup() %>%
arrange(topic, -beta)
academic_top_terms %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(beta, term, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
scale_y_reordered()
install.packages("ggpubr")
install.packages(c("ade4", "adegenet", "ape", "backports", "BH", "brio", "broom", "bslib", "cancensus", "car", "carData", "cli", "conquer", "cpp11", "crayon", "credentials", "crosstalk", "cyclestreets", "data.table", "datamods", "DBI", "deldir", "desc", "devtools", "diffobj", "digest", "DT", "dtplyr", "esquisse", "fansi", "float", "foreign", "fs", "future", "geepack", "generics", "gert", "git2r", "glue", "gmp", "graphlayouts", "hms", "httpuv", "igraph", "influenceR", "ISOcodes", "jqr", "knitr", "lmtest", "lubridate", "lwgeom", "maps", "MatchIt", "matrixStats", "MCMCpack", "memoise", "mime", "ngram", "nloptr", "openssl", "openxlsx", "parallelly", "pillar", "pkgbuild", "pkgload", "plotly", "quanteda", "R.utils", "r5r", "raster", "rcmdcheck", "Rcpp", "RcppArmadillo", "RcppParallel", "readr", "remotes", "rex", "rgdal", "rgeos", "rgrass7", "RhpcBLASctl", "rio", "rJava", "rjson", "rlang", "Rmpfr", "rsparse", "rticles", "rvest", "s2", "sessioninfo", "sf", "shiny", "shinyWidgets", "slam", "sp", "spData", "spdep", "stars", "stopwords", "stringi", "styler", "systemfonts", "testthat", "tibble", "tidyr", "tidytext", "tinytex", "tzdb", "usethis", "uuid", "viridis", "visNetwork", "vroom", "withr", "wk", "xfun", "XML", "xml2"))
install.packages(c("ade4", "adegenet", "ape", "backports", "BH", "brio", "broom", "bslib", "cancensus", "car", "carData", "cli", "conquer", "cpp11", "crayon", "credentials", "crosstalk", "cyclestreets", "data.table", "datamods", "DBI", "deldir", "desc", "devtools", "diffobj", "digest", "DT", "dtplyr", "esquisse", "fansi", "float", "foreign", "fs", "future", "geepack", "generics", "gert", "git2r", "glue", "gmp", "graphlayouts", "hms", "httpuv", "igraph", "influenceR", "ISOcodes", "jqr", "knitr", "lmtest", "lubridate", "lwgeom", "maps", "MatchIt", "matrixStats", "MCMCpack", "memoise", "mime", "ngram", "nloptr", "openssl", "openxlsx", "parallelly", "pillar", "pkgbuild", "pkgload", "plotly", "quanteda", "R.utils", "r5r", "raster", "rcmdcheck", "Rcpp", "RcppArmadillo", "RcppParallel", "readr", "remotes", "rex", "rgdal", "rgeos", "rgrass7", "RhpcBLASctl", "rio", "rJava", "rjson", "rlang", "Rmpfr", "rsparse", "rticles", "rvest", "s2", "sessioninfo", "sf", "shiny", "shinyWidgets", "slam", "sp", "spData", "spdep", "stars", "stopwords", "stringi", "styler", "systemfonts", "testthat", "tibble", "tidyr", "tidytext", "tinytex", "tzdb", "usethis", "uuid", "viridis", "visNetwork", "vroom", "withr", "wk", "xfun", "XML", "xml2"))
install.packages(c("ade4", "adegenet", "ape", "backports", "BH", "brio", "broom", "bslib", "cancensus", "car", "carData", "cli", "conquer", "cpp11", "crayon", "credentials", "crosstalk", "cyclestreets", "data.table", "datamods", "DBI", "deldir", "desc", "devtools", "diffobj", "digest", "DT", "dtplyr", "esquisse", "fansi", "float", "foreign", "fs", "future", "geepack", "generics", "gert", "git2r", "glue", "gmp", "graphlayouts", "hms", "httpuv", "igraph", "influenceR", "ISOcodes", "jqr", "knitr", "lmtest", "lubridate", "lwgeom", "maps", "MatchIt", "matrixStats", "MCMCpack", "memoise", "mime", "ngram", "nloptr", "openssl", "openxlsx", "parallelly", "pillar", "pkgbuild", "pkgload", "plotly", "quanteda", "R.utils", "r5r", "raster", "rcmdcheck", "Rcpp", "RcppArmadillo", "RcppParallel", "readr", "remotes", "rex", "rgdal", "rgeos", "rgrass7", "RhpcBLASctl", "rio", "rJava", "rjson", "rlang", "Rmpfr", "rsparse", "rticles", "rvest", "s2", "sessioninfo", "sf", "shiny", "shinyWidgets", "slam", "sp", "spData", "spdep", "stars", "stopwords", "stringi", "styler", "systemfonts", "testthat", "tibble", "tidyr", "tidytext", "tinytex", "tzdb", "usethis", "uuid", "viridis", "visNetwork", "vroom", "withr", "wk", "xfun", "XML", "xml2"))
install.packages(c("ade4", "adegenet", "ape", "backports", "BH", "brio", "broom", "bslib", "cancensus", "car", "carData", "cli", "conquer", "cpp11", "crayon", "credentials", "crosstalk", "cyclestreets", "data.table", "datamods", "DBI", "deldir", "desc", "devtools", "diffobj", "digest", "DT", "dtplyr", "esquisse", "fansi", "float", "foreign", "fs", "future", "geepack", "generics", "gert", "git2r", "glue", "gmp", "graphlayouts", "hms", "httpuv", "igraph", "influenceR", "ISOcodes", "jqr", "knitr", "lmtest", "lubridate", "lwgeom", "maps", "MatchIt", "matrixStats", "MCMCpack", "memoise", "mime", "ngram", "nloptr", "openssl", "openxlsx", "parallelly", "pillar", "pkgbuild", "pkgload", "plotly", "quanteda", "R.utils", "r5r", "raster", "rcmdcheck", "Rcpp", "RcppArmadillo", "RcppParallel", "readr", "remotes", "rex", "rgdal", "rgeos", "rgrass7", "RhpcBLASctl", "rio", "rJava", "rjson", "rlang", "Rmpfr", "rsparse", "rticles", "rvest", "s2", "sessioninfo", "sf", "shiny", "shinyWidgets", "slam", "sp", "spData", "spdep", "stars", "stopwords", "stringi", "styler", "systemfonts", "testthat", "tibble", "tidyr", "tidytext", "tinytex", "tzdb", "usethis", "uuid", "viridis", "visNetwork", "vroom", "withr", "wk", "xfun", "XML", "xml2"))
install.packages(c("ade4", "adegenet", "ape", "backports", "BH", "brio", "broom", "bslib", "cancensus", "car", "carData", "cli", "conquer", "cpp11", "crayon", "credentials", "crosstalk", "cyclestreets", "data.table", "datamods", "DBI", "deldir", "desc", "devtools", "diffobj", "digest", "DT", "dtplyr", "esquisse", "fansi", "float", "foreign", "fs", "future", "geepack", "generics", "gert", "git2r", "glue", "gmp", "graphlayouts", "hms", "httpuv", "igraph", "influenceR", "ISOcodes", "jqr", "knitr", "lmtest", "lubridate", "lwgeom", "maps", "MatchIt", "matrixStats", "MCMCpack", "memoise", "mime", "ngram", "nloptr", "openssl", "openxlsx", "parallelly", "pillar", "pkgbuild", "pkgload", "plotly", "quanteda", "R.utils", "r5r", "raster", "rcmdcheck", "Rcpp", "RcppArmadillo", "RcppParallel", "readr", "remotes", "rex", "rgdal", "rgeos", "rgrass7", "RhpcBLASctl", "rio", "rJava", "rjson", "rlang", "Rmpfr", "rsparse", "rticles", "rvest", "s2", "sessioninfo", "sf", "shiny", "shinyWidgets", "slam", "sp", "spData", "spdep", "stars", "stopwords", "stringi", "styler", "systemfonts", "testthat", "tibble", "tidyr", "tidytext", "tinytex", "tzdb", "usethis", "uuid", "viridis", "visNetwork", "vroom", "withr", "wk", "xfun", "XML", "xml2"))
install.packages(c("ade4", "adegenet", "ape", "backports", "BH", "brio", "broom", "bslib", "cancensus", "car", "carData", "cli", "conquer", "cpp11", "crayon", "credentials", "crosstalk", "cyclestreets", "data.table", "datamods", "DBI", "deldir", "desc", "devtools", "diffobj", "digest", "DT", "dtplyr", "esquisse", "fansi", "float", "foreign", "fs", "future", "geepack", "generics", "gert", "git2r", "glue", "gmp", "graphlayouts", "hms", "httpuv", "igraph", "influenceR", "ISOcodes", "jqr", "knitr", "lmtest", "lubridate", "lwgeom", "maps", "MatchIt", "matrixStats", "MCMCpack", "memoise", "mime", "ngram", "nloptr", "openssl", "openxlsx", "parallelly", "pillar", "pkgbuild", "pkgload", "plotly", "quanteda", "R.utils", "r5r", "raster", "rcmdcheck", "Rcpp", "RcppArmadillo", "RcppParallel", "readr", "remotes", "rex", "rgdal", "rgeos", "rgrass7", "RhpcBLASctl", "rio", "rJava", "rjson", "rlang", "Rmpfr", "rsparse", "rticles", "rvest", "s2", "sessioninfo", "sf", "shiny", "shinyWidgets", "slam", "sp", "spData", "spdep", "stars", "stopwords", "stringi", "styler", "systemfonts", "testthat", "tibble", "tidyr", "tidytext", "tinytex", "tzdb", "usethis", "uuid", "viridis", "visNetwork", "vroom", "withr", "wk", "xfun", "XML", "xml2"))
install.packages(c("ade4", "adegenet", "ape", "backports", "BH", "brio", "broom", "bslib", "cancensus", "car", "carData", "cli", "conquer", "cpp11", "crayon", "credentials", "crosstalk", "cyclestreets", "data.table", "datamods", "DBI", "deldir", "desc", "devtools", "diffobj", "digest", "DT", "dtplyr", "esquisse", "fansi", "float", "foreign", "fs", "future", "geepack", "generics", "gert", "git2r", "glue", "gmp", "graphlayouts", "hms", "httpuv", "igraph", "influenceR", "ISOcodes", "jqr", "knitr", "lmtest", "lubridate", "lwgeom", "maps", "MatchIt", "matrixStats", "MCMCpack", "memoise", "mime", "ngram", "nloptr", "openssl", "openxlsx", "parallelly", "pillar", "pkgbuild", "pkgload", "plotly", "quanteda", "R.utils", "r5r", "raster", "rcmdcheck", "Rcpp", "RcppArmadillo", "RcppParallel", "readr", "remotes", "rex", "rgdal", "rgeos", "rgrass7", "RhpcBLASctl", "rio", "rJava", "rjson", "rlang", "Rmpfr", "rsparse", "rticles", "rvest", "s2", "sessioninfo", "sf", "shiny", "shinyWidgets", "slam", "sp", "spData", "spdep", "stars", "stopwords", "stringi", "styler", "systemfonts", "testthat", "tibble", "tidyr", "tidytext", "tinytex", "tzdb", "usethis", "uuid", "viridis", "visNetwork", "vroom", "withr", "wk", "xfun", "XML", "xml2"))
heart.data <- read.csv("~/2021-22/Regression Analysis/heart.data.csv")
View(heart.data)
income.data <- read.csv("~/2021-22/Regression Analysis/income.data.csv")
View(income.data)
rm(list = ls())
heart.data <- read.csv("~/2021-22/Regression Analysis/heart.data.csv")
View(heart.data)
income.data <- read.csv("~/2021-22/Regression Analysis/income.data.csv")
View(income.data)
library(ggplot2)
library(dplyr)
library(broom)
library(ggpubr)
summary(income.data)
summary(heart.data)
hist(income.data$happiness)
plot(happiness ~ income, data = income.data)
summary(heart.data)
cor(heart.data$biking, heart.data$smoking)
hist(heart.data$heart.disease)
plot(heart.disease ~ smoking, data = heart.data)
plot(heart.disease ~ biking, data = heart.data)
income.happiness.lm <- lm(happiness ~ income, data = income.data)
summary(income.happiness.lm)
income.happiness.lm <- lm(happiness ~ income, data = income.data)
summary(income.happiness.lm)
heart.disease.lm<-lm(heart.disease ~ biking + smoking, data = heart.data)
summary(heart.disease.lm)
rm(list = ls())
library(DiagrammeR)
library(dplyr)
library(ggraph)
library(ggplot2)
library(igraph)
library(kableExtra)
library(pdftools)
library(readr)
library(reshape2)
library(stringr)
library(text2vec)
library(textdata)
library(tidyr)
library(tidytext)
library(tm)
library(tools)
library(topicmodels)
library(widyr)
library(word2vec)
library(wordcloud)
library(ldatuning)
library(quanteda)
load(file= "Corpus .rda/academic_corpus_repaired.rda")
load(file= "Corpus .rda/municipal_corpus.rda")
load(file= "Corpus .rda/consortium_corpus.rda")
load(file= "Corpus .rda/school_corpus.rda")
load(file= "Corpus .rda/policy_corpus.rda")
load(file= "Corpus .rda/raw_policy_corpus.rda")
# This function is used to write a bibliography for the `R` packages used in the paper
knitr::write_bib(file = 'packages.bib')
data_tbl <- data.frame(
Stakeholder = c("School boards", "Municipalities", "Transportation consortia"),
Total = c("62", "62", "39"),
Included = c("32", "28", "9")
)
kable(data_tbl,
"latex",
booktabs = TRUE,
caption = "\\label{tab:search-results}Search results from the main STP stakeholder groups.") %>%
kable_paper(full_width = F) %>%
column_spec(1, bold = T, border_right = T) %>%
column_spec(3, border_left = T) %>%
kable_styling(latex_options = c("striped", "scale_down"))
# Create new data frame with the cleaned corpus
MunicipalTextDF <- data.frame(text = sapply(municipal_corpus, as.character), stringsAsFactors = FALSE)
municipal_it_train = itoken(MunicipalTextDF$text, progressbar = FALSE)
municipal_vocab = create_vocabulary(municipal_it_train)
# Cut out terms that have a minimum count of 1
municipal_vocab <- prune_vocabulary(municipal_vocab, term_count_min = 1)
# Create new data frame with the cleaned corpus
ConsortiumTextDF <- data.frame(text = sapply(consortium_corpus, as.character), stringsAsFactors = FALSE)
consortium_it_train = itoken(ConsortiumTextDF$text, progressbar = FALSE)
consortium_vocab = create_vocabulary(consortium_it_train)
# Cut out terms that have a minimum count of 1
consortium_vocab <- prune_vocabulary(consortium_vocab, term_count_min = 1)
# Create new data frame with the cleaned corpus
SchoolTextDF <- data.frame(text = sapply(school_corpus, as.character), stringsAsFactors = FALSE)
school_it_train = itoken(SchoolTextDF$text, progressbar = FALSE)
school_vocab = create_vocabulary(school_it_train)
# Cut out terms that have a minimum count of 1
school_vocab <- prune_vocabulary(school_vocab, term_count_min = 1)
# Create new data frame with the cleaned corpus
AcademicTextDF <- data.frame(text = sapply(academic_corpus_repaired, as.character), stringsAsFactors = FALSE)
it_train = itoken(AcademicTextDF$text, progressbar = FALSE)
academic_vocab = create_vocabulary(it_train)
# Cut out terms that have a minimum count of 100
academic_vocab <- prune_vocabulary(academic_vocab, term_count_min = 100)
municipal_words <- municipal_vocab %>% slice(1938:1914)
school_words <- school_vocab %>% slice(1812:1788)
consortia_words <- consortium_vocab[-c(971),] %>% slice(993:968)
academic_words <- academic_vocab[-c(1289, 1284),] %>% slice(1291:1265)
top_words <- cbind(
municipal_words,
school_words,
consortia_words,
academic_words)
colnames(top_words) <- c("Term", "Count (n)", "Documents (n)", "Term", "Count (n)", "Documents (n)", "Term", "Count (n)", "Documents (n)", "Term", "Count (n)", "Documents (n)")
# add frequency term count / words
kable(top_words,
"latex",
booktabs = TRUE,
col.names = c("Term",
"Count (n)",
"Documents (n)",
"Term",
"Count (n)",
"Documents (n)",
"Term",
"Count (n)",
"Documents (n)",
"Term",
"Count (n)",
"Documents (n)"),
align = c("l", "c", "c", "l", "c", "c", "l", "c", "c", "l", "c", "c"),
caption = "\\label{tab:word-table}Top 25 terms identified in each corpora. Document frequencies are also indicated.") %>%
kable_styling(latex_options = c("striped", "scale_down")) %>%
add_header_above(c("Municipalities" = 3, "School Boards" = 3, "Transportation Consortia" = 3, "Academic Papers" = 3)) %>%
footnote(general = " ",
alphabet = c("Count (n) refers to the total number of times the term is found in the corpora", "Documents (n) refers to the total number of documents that feature the term"))
# Converting corpus to tidytext data type
td_municipal_corpus <- tidy(municipal_corpus)
# n can be changed
municipal_bigrams <- td_municipal_corpus %>%
unnest_tokens(bigram, text, token = "ngrams", n = 2)
municipal_trigrams <- td_municipal_corpus %>%
unnest_tokens(trigram, text, token = "ngrams", n = 3)
# Bigrams and trigrams that are most common
top_municipal_bigrams <- municipal_bigrams %>%
count(bigram, sort = TRUE)
top_municipal_trigrams <- municipal_trigrams %>%
count(trigram, sort = TRUE)
# Converting corpus to tidytext data type
td_consortium_corpus <- tidy(consortium_corpus)
# n can be changed
consortium_bigrams <- td_consortium_corpus %>%
unnest_tokens(bigram, text, token = "ngrams", n = 2)
consortium_trigrams <- td_consortium_corpus %>%
unnest_tokens(trigram, text, token = "ngrams", n = 3)
# Bigrams and trigrams that are most common
top_consortium_bigrams <- consortium_bigrams %>%
count(bigram, sort = TRUE)
top_consortium_trigrams <- consortium_trigrams %>%
count(trigram, sort = TRUE)
# Converting corpus to tidytext data type
td_school_corpus <- tidy(school_corpus)
# n can be changed
school_bigrams <- td_school_corpus %>%
unnest_tokens(bigram, text, token = "ngrams", n = 2)
school_trigrams <- td_school_corpus %>%
unnest_tokens(trigram, text, token = "ngrams", n = 3)
# Bigrams and trigrams that are most common
top_school_bigrams <- school_bigrams %>%
count(bigram, sort = TRUE)
top_school_trigrams <- school_trigrams %>%
count(trigram, sort = TRUE)
# Converting corpus to tidytext data type
td_policy_corpus <- tidy(policy_corpus)
# n can be changed
policy_bigrams <- td_policy_corpus %>%
unnest_tokens(bigram, text, token = "ngrams", n = 2)
policy_trigrams <- td_policy_corpus %>%
unnest_tokens(trigram, text, token = "ngrams", n = 3)
# Bigrams and trigrams that are most common
top_policy_bigrams <- policy_bigrams %>%
count(bigram, sort = TRUE)
top_policy_trigrams <- policy_trigrams %>%
count(trigram, sort = TRUE)
# Converting corpus to tidytext data type
td_academic_corpus <- tidy(academic_corpus_repaired)
# n can be changed
academic_bigrams <- td_academic_corpus %>%
unnest_tokens(bigram, text, token = "ngrams", n = 2)
academic_trigrams <- td_academic_corpus %>%
unnest_tokens(trigram, text, token = "ngrams", n = 3)
# Bigrams and trigrams that are most common
top_academic_bigrams <- academic_bigrams %>%
count(bigram, sort = TRUE)
top_academic_trigrams <- academic_trigrams %>%
count(trigram, sort = TRUE)
municipal_bigrams_separated <- municipal_bigrams %>%
separate(bigram, c("word1", "word2"), sep = " ")
municipal_bigram_counts <- municipal_bigrams_separated %>%
count(word1, word2, sort = TRUE)
# Adjust the parameter below to filter out based on number of occurrence
# Error will occur if n is outide the range of occurrences
municipal_bigram_graph <- municipal_bigram_counts %>%
filter(n > 8) %>%
graph_from_data_frame()
set.seed(2021)
a <- grid::arrow(type = "closed", length = unit(.15, "inches"))
MunicipalTextDF <- data.frame(text = sapply(municipal_corpus, as.character), stringsAsFactors = FALSE)
M_it_train = itoken(MunicipalTextDF$text, progressbar = FALSE)
municipal_vocab = create_vocabulary(M_it_train)
municipal_vocab <- prune_vocabulary(municipal_vocab, term_count_min = 5)
municipal_vocab
ConsortiumTextDF <- data.frame(text = sapply(consortium_corpus, as.character), stringsAsFactors = FALSE)
C_it_train = itoken(ConsortiumTextDF$text, progressbar = FALSE)
consortium_vocab = create_vocabulary(C_it_train)
consortium_vocab <- prune_vocabulary(consortium_vocab, term_count_min = 5)
consortium_vocab
SchoolTextDF <- data.frame(text = sapply(school_corpus, as.character), stringsAsFactors = FALSE)
S_it_train = itoken(SchoolTextDF$text, progressbar = FALSE)
school_vocab = create_vocabulary(S_it_train)
school_vocab <- prune_vocabulary(school_vocab, term_count_min = 5)
school_vocab
PolicyTextDF <- data.frame(text = sapply(policy_corpus, as.character), stringsAsFactors = FALSE)
P_it_train = itoken(PolicyTextDF$text, progressbar = FALSE)
policy_vocab = create_vocabulary(P_it_train)
policy_vocab <- prune_vocabulary(policy_vocab, term_count_min = 5)
policy_vocab
ggraph(municipal_bigram_graph, layout = "fr") +
geom_edge_link(aes(edge_alpha = n), show.legend = FALSE,
arrow = a, end_cap = circle(.07, 'inches')) +
geom_node_point(color = "lightblue", size = 4) +
geom_node_text(aes(label = name), repel = TRUE) +
theme_void()
consortium_bigrams_separated <- consortium_bigrams %>%
separate(bigram, c("word1", "word2"), sep = " ")
consortium_bigram_counts <- consortium_bigrams_separated %>%
count(word1, word2, sort = TRUE)
# Adjust the parameter below to filter out based on number of occurrence
# Error will occur if n is outide the range of occurrences
consortium_bigram_graph <- consortium_bigram_counts %>%
filter(n > 5) %>%
graph_from_data_frame()
set.seed(2021)
a <- grid::arrow(type = "closed", length = unit(.15, "inches"))
ggraph(consortium_bigram_graph, layout = "fr") +
geom_edge_link(aes(edge_alpha = n), show.legend = FALSE,
arrow = a, end_cap = circle(.07, 'inches')) +
geom_node_point(color = "red", size = 4) +
geom_node_text(aes(label = name), repel = TRUE) +
theme_void()
school_bigrams_separated <- school_bigrams %>%
separate(bigram, c("word1", "word2"), sep = " ")
school_bigram_counts <- school_bigrams_separated %>%
count(word1, word2, sort = TRUE)
# Adjust the parameter below to filter out based on number of occurrence
# Error will occur if n is outide the range of occurrences
school_bigram_graph <- school_bigram_counts %>%
filter(n > 8) %>%
graph_from_data_frame()
set.seed(2021)
a <- grid::arrow(type = "closed", length = unit(.15, "inches"))
ggraph(school_bigram_graph, layout = "fr") +
geom_edge_link(aes(edge_alpha = n), show.legend = FALSE,
arrow = a, end_cap = circle(.07, 'inches')) +
geom_node_point(color = "orange", size = 4) +
geom_node_text(aes(label = name), repel = TRUE) +
theme_void()
policy_bigrams_separated <- policy_bigrams %>%
separate(bigram, c("word1", "word2"), sep = " ")
policy_bigram_counts <- policy_bigrams_separated %>%
count(word1, word2, sort = TRUE)
# Adjust the parameter below to filter out based on number of occurrence
# Error will occur if n is outide the range of occurrences
policy_bigram_graph <- policy_bigram_counts %>%
filter(n > 10) %>%
graph_from_data_frame()
set.seed(2021)
a <- grid::arrow(type = "closed", length = unit(.15, "inches"))
ggraph(policy_bigram_graph, layout = "fr") +
geom_edge_link(aes(edge_alpha = n), show.legend = FALSE,
arrow = a, end_cap = circle(.07, 'inches')) +
geom_node_point(color = "purple", size = 4) +
geom_node_text(aes(label = name), repel = TRUE) +
theme_void()
academic_bigrams_separated <- academic_bigrams %>%
separate(bigram, c("word1", "word2"), sep = " ")
academic_bigram_counts <- academic_bigrams_separated %>%
count(word1, word2, sort = TRUE)
# Adjust the parameter below to filter out based on number of occurrence
# Error will occur if n is outside the range of occurrences
academic_bigram_graph <- academic_bigram_counts %>%
filter(n > 200) %>%
graph_from_data_frame()
set.seed(2021)
a <- grid::arrow(type = "closed", length = unit(.15, "inches"))
ggraph(academic_bigram_graph, layout = "fr") +
geom_edge_link(aes(edge_alpha = n), show.legend = FALSE,
arrow = a, end_cap = circle(.07, 'inches')) +
geom_node_point(color = "lightgreen", size = 4) +
geom_node_text(aes(label = name), repel = TRUE) +
theme_void()
# Import raw policy VCorpus (not cleaned of stop words or punctuation) created by tm package
policy_quanteda <- tm::VCorpus(tm::VectorSource(raw_policy_corpus))
policy_quanteda <- corpus(policy_quanteda)
# Extraction of various search terms and the surrounding sentence context
kwic_pol_physical <- kwic(tokens(policy_quanteda), pattern = "physical", window = 10)
kwic_pol_mental <- kwic(tokens(policy_quanteda), pattern = "mental", window = 10)
kwic_pol_air <- kwic(tokens(policy_quanteda), pattern = "air", window = 10)
kwic_pol_traffic <- kwic(tokens(policy_quanteda), pattern = "traffic", window = 10)
kwic_pol_safety <- kwic(tokens(policy_quanteda), pattern = "safety", window = 10)
kwic_pol_health <- kwic(tokens(policy_quanteda), pattern = "health", window = 10)
kwic_pol_emissions <- kwic(tokens(policy_quanteda), pattern = "emissions", window = 10)
kwic_pol_routes <- kwic(tokens(policy_quanteda), pattern = "routes", window = 10)
kwic_pol_lanes <- kwic(tokens(policy_quanteda), pattern = "lanes", window = 10)
kwic_pol_zone <- kwic(tokens(policy_quanteda), pattern = "zone", window = 10)
kwic_pol_bus <- kwic(tokens(policy_quanteda), pattern = "bus", window = 10)
kwic_pol_comm <- kwic(tokens(policy_quanteda), pattern = "community", window = 10)
kwic_pol_ben <- kwic(tokens(policy_quanteda), pattern = "benefit", window = 10)
kwic_pol_wea <- kwic(tokens(policy_quanteda), pattern = "weather", window = 10)
text_tbl <- data.frame(
Terms = c("Air Quality", "Benefit", "Walking School Bus", "Community", "Emissions", "Health", "Lanes", "Mental Health", "Physical Health"),
Stakeholder = c("School Board", "Municipality", "School Board", "School Board", "Consortia", "Municipality", "Municipality", "Municipality", "Municipality"),
Context = c(
"Active transportation [...] improves air quality.",
"Stronger bones and muscles, improved self-esteem and sense of well-being while reducing stress and risk of chronic disease all benefit those who use active transportation.",
"While taking part in a walking school bus, your child will enjoy seeing friends on the way to school. They will be active more often. This is also a great opportunity for your child to socialize with school friends in a monitored and safe way where they can practice social distancing, modelled by a leader.",
"Help your students get started on the right foot - encourage them to walk or bike to school when possible. Even leaving the car a block or two and walking the rest of the way helps. It’s good for the environment and your health, and teaches your child independence and community awareness.",
"An active school commute also reduces congestion in school zones and contributes to reducing greenhouse gas emissions – it’s a win-win for everyone!",
"Active School Travel allows school-aged children the chance to participate in moderate to intense physical activity. This is linked with lower body mass index and improved cardiovascular health.",
"We are continuing to build on the cycling and pedestrian network by adding more bike lanes, building multi-use paths and encouraging developments to provide better pedestrian/cycling environments.",
"ASST not only improves physical and mental health but contributes to a healthier environment and safer streets.",
"Encouraging Active Transportation promotes personal health and recreation, helps manage congestion, reduces emissions and supports municipal objectives for efficient land use.")
)
kbl(text_tbl,
booktabs = TRUE,
caption = "\\label{tab:policy-concordance}The context of key terms that were identified as common bigrams.") %>%
kable_paper(full_width = F) %>%
kable_styling(latex_options = c("striped")) %>%
column_spec(1, bold = T) %>%
column_spec(3, width = "20em")
# Create DTM from corpus
municipal_dtm <- DocumentTermMatrix(municipal_corpus)
school_dtm <- DocumentTermMatrix(school_corpus)
consortia_dtm <- DocumentTermMatrix(consortium_corpus)
policy_dtm <- DocumentTermMatrix(policy_corpus)
academic_dtm <- DocumentTermMatrix(academic_corpus_repaired)
# Select number of topics for each LDA model using `ldatuning`
municipal_lda_num <- FindTopicsNumber(
municipal_dtm,
topics = seq(from = 2, to = 15, by = 1),
metrics = c("Griffiths2004", "CaoJuan2009", "Arun2010", "Deveaud2014"),
method = "Gibbs",
#control = list(seed = 77),
#mc.cores = 2L,
#verbose = TRUE
)
school_lda_num <- FindTopicsNumber(
school_dtm,
topics = seq(from = 2, to = 15, by = 1),
metrics = c("Griffiths2004", "CaoJuan2009", "Arun2010", "Deveaud2014"),
method = "Gibbs",
#control = list(seed = 77),
#mc.cores = 2L,
#verbose = TRUE
)
consortia_lda_num <- FindTopicsNumber(
consortia_dtm,
topics = seq(from = 2, to = 15, by = 1),
metrics = c("Griffiths2004", "CaoJuan2009", "Arun2010", "Deveaud2014"),
method = "Gibbs",
#control = list(seed = 77),
#mc.cores = 2L,
#verbose = TRUE
)
policy_lda_num <- FindTopicsNumber(
policy_dtm,
topics = seq(from = 2, to = 15, by = 1),
metrics = c("Griffiths2004", "CaoJuan2009", "Arun2010", "Deveaud2014"),
method = "Gibbs",
#control = list(seed = 77),
#mc.cores = 2L,
#verbose = TRUE
)
#DO NOT RUN EVERY TIME - takes approximately 20 minutes
academic_lda_num <- FindTopicsNumber(
academic_dtm,
topics = seq(from = 2, to = 25, by = 1),
metrics = c("Griffiths2004", "CaoJuan2009", "Arun2010", "Deveaud2014"),
method = "Gibbs")
#control = list(seed = 77),
#mc.cores = 2L,
#verbose = TRUE)
FindTopicsNumber_plot(municipal_lda_num)
FindTopicsNumber_plot(school_lda_num)
FindTopicsNumber_plot(consortia_lda_num)
FindTopicsNumber_plot(policy_lda_num)
FindTopicsNumber_plot(academic_lda_num)
# The graphs suggest that there are 4 topics for the municipal corpora
# The graphs suggest that there are 4 topics for the school corpora
# The graphs suggest that there are 4 topics for the municipal corpora
# The graphs suggest that there are 5 topics for the policy corpora
# The graphs suggest that there are 17 topics for the academic corpora
municipal_lda <- LDA(municipal_dtm, k = 4, method = "Gibbs", control = NULL, model = NULL)
school_lda <- LDA(school_dtm, k = 4, method = "Gibbs", control = NULL, model = NULL)
consortia_lda <- LDA(consortia_dtm, k = 4, method = "Gibbs", control = NULL, model = NULL)
policy_lda <- LDA(policy_dtm, k = 7, method = "Gibbs", control = NULL, model = NULL)
academic_lda <- LDA(academic_dtm, k = 11, method = "Gibbs", control = NULL, model = NULL)
municipal_topics <- tidy(municipal_lda, matrix = "beta")
school_topics <- tidy(school_lda, matrix = "beta")
consortia_topics <- tidy(consortia_lda, matrix = "beta")
policy_topics <- tidy(policy_lda, matrix = "beta")
academic_topics <- tidy(academic_lda, matrix = "beta")
municipal_top_terms <- municipal_topics %>%
group_by(topic) %>%
slice_max(beta, n = 10) %>%
ungroup() %>%
arrange(topic, -beta)
municipal_top_terms %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(beta, term, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
scale_y_reordered()
school_top_terms <- school_topics %>%
group_by(topic) %>%
slice_max(beta, n = 10) %>%
ungroup() %>%
arrange(topic, -beta)
school_top_terms %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(beta, term, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
scale_y_reordered()
consortia_top_terms <- consortia_topics %>%
group_by(topic) %>%
slice_max(beta, n = 10) %>%
ungroup() %>%
arrange(topic, -beta)
consortia_top_terms %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(beta, term, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
scale_y_reordered()
policy_top_terms <- policy_topics %>%
group_by(topic) %>%
slice_max(beta, n = 10) %>%
ungroup() %>%
arrange(topic, -beta)
policy_top_terms %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(beta, term, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
scale_y_reordered()
academic_top_terms <- academic_topics %>%
group_by(topic) %>%
slice_max(beta, n = 10) %>%
ungroup() %>%
arrange(topic, -beta)
academic_top_terms %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(beta, term, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
scale_y_reordered()
ggraph(policy_bigram_graph, layout = "fr") +
geom_edge_link(aes(edge_alpha = n), show.legend = FALSE,
arrow = a, end_cap = circle(.07, 'inches')) +
geom_node_point(color = "purple", size = 4) +
geom_node_text(aes(label = name), repel = TRUE) +
theme_void()
